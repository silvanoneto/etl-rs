# üöÄ ETLRS - Framework ETL Moderno em Rust

[![Rust](https://img.shields.io/badge/rust-%23000000.svg?style=for-the-badge&logo=rust&logoColor=white)](https://www.rust-lang.org/)
[![License: Apache](https://img.shields.io/badge/License-Apache-yellow.svg)](./LICENSE)
[![Crates.io](https://img.shields.io/crates/v/etlrs.svg)](https://crates.io/crates/etlrs)

Uma biblioteca ETL moderna, segura e de alta performance constru√≠da em Rust, com foco em type-safety, observabilidade e facilidade de uso para processamento de dados.

## ‚ú® Caracter√≠sticas Principais

- üöÑ **Alta Performance**: Processamento ass√≠ncrono com Tokio e paraleliza√ß√£o
- üîí **Type Safety**: Sistema de tipos rigoroso com valida√ß√£o em tempo de compila√ß√£o  
- ÔøΩ **M√∫ltiplos Formatos**: CSV, JSON, JSON Lines, Parquet (opcional)
- üîÑ **Processamento em Lotes**: Suporte para datasets grandes com batch processing
- ÔøΩ **API Fluente**: Builder pattern intuitivo para constru√ß√£o de pipelines
- üìà **Observabilidade**: M√©tricas integradas, eventos e logging estruturado
- ÔøΩÔ∏è **Extens√≠vel**: Sistema de traits para componentes customizados
- üß™ **Test√°vel**: Componentes de teste (MemoryLoader, ConsoleLoader)

## üìö Documenta√ß√£o

### üéØ In√≠cio R√°pido
- [Vis√£o Geral do Sistema](./docs/context/01-visao-geral.md) - Introdu√ß√£o e objetivos do ETLRS
- [Estrutura do Projeto](./docs/context/02-estrutura-projeto.md) - Organiza√ß√£o e componentes
- [Depend√™ncias e Setup](./docs/context/03-dependencias.md) - Configura√ß√£o inicial

### üèóÔ∏è Arquitetura e Design  
- [Arquitetura Principal](./docs/context/04-arquitetura-principal.md) - Componentes core
- [Framework de Integridade](./docs/context/05-framework-integridade.md) - Valida√ß√£o e qualidade
- [Recursos Avan√ßados](./docs/context/06-recursos-avancados.md) - Features enterprise

### ÔøΩ Guias T√©cnicos
- [Guia de Performance](./docs/performance.md) - Otimiza√ß√£o e tuning
- [Troubleshooting](./docs/troubleshooting.md) - Resolu√ß√£o de problemas
- [Manuten√ß√£o e Gest√£o](./docs/context/07-manutencao-gestao.md) - Opera√ß√µes cont√≠nuas

## üöÄ Quick Start

### Instala√ß√£o

```toml
[dependencies]
etlrs = "0.1.0"

# Para suporte Parquet
etlrs = { version = "0.1.0", features = ["parquet"] }

# Para suporte CSV
etlrs = { version = "0.1.0", features = ["csv"] }
```

### Exemplo B√°sico

```rust
use etlrs::prelude::*;

#[tokio::main]
async fn main() -> Result<()> {
    // Configura logging
    tracing_subscriber::fmt::init();
    
    // Criar pipeline ETL simples
    let pipeline = Pipeline::builder()
        .extract(CsvExtractor::new("data/users.csv"))
        .transform(FilterTransform::new(|row| {
            row.get("age")
                .and_then(|v| v.as_integer())
                .unwrap_or(0) >= 18
        }))
        .load(JsonLoader::new("data/adults.json").with_pretty(true))
        .build();
    
    // Executar pipeline
    let result = pipeline.execute().await?;
    
    println!("Pipeline executado com sucesso!");
    println!("Registros processados: {}", result.rows_processed);
    println!("Registros bem-sucedidos: {}", result.rows_successful);
    println!("Tempo de execu√ß√£o: {}ms", result.execution_time_ms);
    
    Ok(())
}
```

### Exemplo com M√∫ltiplas Transforma√ß√µes

```rust
use etlrs::prelude::*;

#[tokio::main]
async fn main() -> Result<()> {
    let pipeline = Pipeline::builder()
        .extract(CsvExtractor::new("sales.csv"))
        .transform(CompositeTransformer::new()
            // Filtrar vendas acima de R$ 100
            .add(FilterTransform::new(|row| {
                row.get("amount")
                    .and_then(|v| v.as_float())
                    .unwrap_or(0.0) > 100.0
            }))
            // Adicionar coluna calculada
            .add(MapTransform::new(|mut row| {
                if let Some(amount) = row.get("amount").and_then(|v| v.as_float()) {
                    row.insert("tax".to_string(), DataValue::Float(amount * 0.1));
                }
                row
            }))
            // Renomear colunas
            .add(RenameColumnsTransform::new(
                [("amount".to_string(), "valor".to_string())]
                    .into_iter().collect()
            ))
        )
        .load(JsonLinesLoader::new("vendas_processadas.jsonl"))
        .build();

    let result = pipeline.execute().await?;
    println!("Processadas {} vendas", result.rows_processed);
    
    Ok(())
}
```

## üõ†Ô∏è Instala√ß√£o e Setup

### Pr√©-requisitos

- Rust 1.75+ (stable)
- Cargo

### Clone e Build

```bash
# Clone o reposit√≥rio
git clone https://github.com/silvanoneto/etlrs.git
cd etlrs

# Build do projeto
cargo build --release

# Executar testes
cargo test

# Executar testes com features
cargo test --features parquet
```

### Features Dispon√≠veis

```toml
[dependencies]
etlrs = { version = "0.1.0", features = ["csv", "parquet"] }

# Features suportadas:
# - csv: Suporte para arquivos CSV
# - parquet: Suporte para arquivos Parquet (Apache Arrow 55.2.0)
# - delta: Suporte para Delta Lake (experimental)
```

## üìä Componentes Dispon√≠veis

### üîå Extractors (Extra√ß√£o)
- **CsvExtractor**: Leitura de arquivos CSV com configura√ß√£o flex√≠vel
- **JsonExtractor**: Leitura de arquivos JSON e JSON Lines
- **ParquetExtractor**: Leitura de arquivos Parquet (feature `parquet`)

### üîÑ Transformers (Transforma√ß√£o)
- **FilterTransform**: Filtragem de dados com predicados customizados
- **MapTransform**: Transforma√ß√£o de dados linha por linha
- **AsyncMapTransform**: Transforma√ß√£o ass√≠ncrona para opera√ß√µes I/O
- **AddColumnTransform**: Adi√ß√£o de colunas com valores constantes
- **RemoveColumnsTransform**: Remo√ß√£o de colunas espec√≠ficas
- **SelectColumnsTransform**: Sele√ß√£o de colunas espec√≠ficas
- **RenameColumnsTransform**: Renomea√ß√£o de colunas
- **ConvertTypesTransform**: Convers√£o de tipos de dados
- **AggregateTransform**: Agrega√ß√µes (count, sum, avg, min, max)
- **CompositeTransformer**: Combina√ß√£o de m√∫ltiplas transforma√ß√µes
- **ParallelTransform**: Processamento paralelo

### üìÅ Loaders (Carregamento)
- **JsonLoader**: Escrita para arquivos JSON
- **JsonLinesLoader**: Escrita para arquivos JSON Lines
- **ConsoleLoader**: Output para console (√∫til para debug)
- **MemoryLoader**: Armazenamento em mem√≥ria (√∫til para testes)
- **ParquetLoader**: Escrita para arquivos Parquet (feature `parquet`)

### üéØ Casos de Uso Implementados

#### 1. Processamento de CSV para JSON
```rust
let pipeline = Pipeline::builder()
    .extract(CsvExtractor::new("input.csv"))
    .transform(FilterTransform::new(|row| {
        row.get("status") == Some(&DataValue::String("active".to_string()))
    }))
    .load(JsonLoader::new("output.json").with_pretty(true))
    .build();
```

#### 2. Agrega√ß√£o de Dados
```rust
let pipeline = Pipeline::builder()
    .extract(CsvExtractor::new("sales.csv"))
    .transform(AggregateTransform::new(
        vec!["product_category".to_string()], // group by
        [("amount".to_string(), AggregateFunction::Sum)].into()
    ))
    .load(JsonLoader::new("summary.json"))
    .build();
```

#### 3. Processamento em Lotes
```rust
// Para datasets grandes
let result = pipeline.execute_batch(1000).await?;
```

#### 4. Multiple Outputs
```rust
// Usando exemplo de MultiLoader personalizado
let multi_loader = MultiLoader::new(vec![
    Box::new(JsonLoader::new("output.json")),
    Box::new(ConsoleLoader::new()),
    Box::new(MemoryLoader::new()),
]);
```

## üß™ Testing

```bash
# Executar todos os testes
cargo test

# Testes com features espec√≠ficas
cargo test --features parquet

# Testes com output verbose
cargo test -- --nocapture

# Executar exemplos
cargo run --example basic_pipeline
cargo run --example advanced_pipeline
```

## üéØ Benchmarks

```bash
# Executar benchmarks
cargo bench

# Benchmark espec√≠fico
cargo bench pipeline_throughput
```

## üìà Observabilidade

### M√©tricas Integradas
```rust
// Acessar m√©tricas do pipeline
let metrics = pipeline.get_metrics().await;
println!("Execu√ß√µes: {}", metrics.executions.len());
println!("Taxa de sucesso: {:.2}%", metrics.success_rate * 100.0);
println!("Total processado: {}", metrics.total_rows_processed);
```

### Estados do Pipeline
```rust
// Verificar estado atual
let state = pipeline.current_state();
println!("Estado: {:?}", state); // Idle, Extracting, Transforming, Loading, etc.
```

### Eventos e Logging
```rust
// Configurar logging estruturado
tracing_subscriber::fmt::init();

// Pipeline emite eventos automaticamente para PipelineEvent::Started, 
// PipelineEvent::Completed, PipelineEvent::Error, etc.
```

## ü§ù Contribuindo

Contribui√ß√µes s√£o bem-vindas! Para contribuir:

1. Fork o projeto
2. Crie sua feature branch (`git checkout -b feature/MinhaFeature`)
3. Fa√ßa commit das suas mudan√ßas (`git commit -m 'Adiciona MinhaFeature'`)
4. Push para a branch (`git push origin feature/MinhaFeature`)
5. Abra um Pull Request

### Desenvolvimento

```bash
# Instalar depend√™ncias de desenvolvimento
cargo install cargo-watch cargo-expand

# Executar verifica√ß√µes
cargo fmt --check
cargo clippy -- -D warnings

# Watch mode para desenvolvimento
cargo watch -x test
```

## üìä Status do Projeto

### Recursos Implementados ‚úÖ

- [x] Core ETL Engine com Pipeline Builder
- [x] Extractors: CSV, JSON, Parquet
- [x] Transformers: Filter, Map, Aggregate, Select, Rename, etc.
- [x] Loaders: JSON, JSON Lines, Console, Memory, Parquet
- [x] Batch Processing
- [x] M√©tricas e Observabilidade
- [x] Error Handling robusto
- [x] Sistema de Eventos
- [x] Processamento Paralelo
- [x] Type-safe DataValue System

### Roadmap Futuro üöß

- [ ] Database Connectors (PostgreSQL, MySQL)
- [ ] Cloud Storage (S3, Azure Blob)
- [ ] Streaming Processing
- [ ] Delta Lake Integration completa
- [ ] Schema Evolution
- [ ] Data Quality Framework
- [ ] Web Dashboard
- [ ] Kubernetes Operator

### Vers√µes Suportadas

| Vers√£o | Status | Rust M√≠nimo |
|--------|--------|-------------|
| 0.1.x  | ‚úÖ Ativa | 1.75+ |

## üìù Licen√ßa

Este projeto est√° licenciado sob a Apache License 2.0 - veja o arquivo [LICENSE](LICENSE) para detalhes.

## üôè Agradecimentos

- Comunidade Rust por ferramentas e bibliotecas incr√≠veis
- Projeto Apache Arrow para suporte Parquet
- Contribuidores e usu√°rios que fornecem feedback valioso

## üìû Contato

- **Autor**: Silvano Neto
- **Email**: dev@silvanoneto.com
- **GitHub**: [@silvanoneto](https://github.com/silvanoneto)

---

<p align="center">
  Feito com ‚ù§Ô∏è e Rust ü¶Ä
  <br>
  <a href="#-etlrs---framework-etl-moderno-em-rust">Voltar ao topo</a>
</p>
